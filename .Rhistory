d_prime = c(dt_fin_f0,
dt_fin_du,
dt_fin_ext,
dt_fin_int,
dt_fin_int_ext,
dt_prenu_f0,
dt_prenu_ext,
dt_prenu_int,
dt_prenu_int_ext,
dt_glo_diff_f0,
dt_glo_diff_f0_int),
Reliability = c(reli_fin_f0,
reli_fin_du,
reli_fin_ext,
reli_fin_int,
reli_fin_int_ext,
reli_prenu_f0,
reli_prenu_ext_f0,
reli_prenu_int_f0,
reli_prenu_int_ext_f0,
reli_glo_diff_f0,
reli_glo_diff_f0_int))
d_prime_results$Reliability <- round(d_prime_results$Reliability, 3)
return(d_prime_results)
}
d_prime_results_IViE <- calculate_d_prime_results(dt_fin_f0_IViE, dt_fin_du_IViE, dt_fin_ext_IViE, dt_fin_int_IViE, dt_fin_int_ext_IViE,
dt_prenu_f0_IViE, dt_prenu_ext_IViE, dt_prenu_int_IViE, dt_prenu_int_ext_IViE,
dt_glo_diff_f0_IViE, dt_glo_diff_f0_int_IViE, sum_d_prime_IViE)
d_prime_results_SVBI <- calculate_d_prime_results(dt_fin_f0_SVBI, dt_fin_du_SVBI, dt_fin_ext_SVBI, dt_fin_int_SVBI, dt_fin_int_ext_SVBI,
dt_prenu_f0_SVBI, dt_prenu_ext_SVBI, dt_prenu_int_SVBI, dt_prenu_int_ext_SVBI,
dt_glo_diff_f0_SVBI, dt_glo_diff_f0_int_SVBI, sum_d_prime_SVBI)
d_prime_results_IViE
rownames(d_prime_results_IViE) <- NULL
d_prime_results_SVBI
rownames(d_prime_results_SVBI) <- NULL
knitr::kable(d_prime_results_IViE)
knitr::kable(d_prime_results_SVBI)
####Research Question 1: Scatter plots
# A list for all acoustic cues used in the analysis
acoustic_cues <- c("final_F0",
"final_duration",
"fin_ExtNormalization",
"fin_IntNormalization",
"fin_Int_Ext_Normalization",
"prenuclear_F0",
"prenu_ExtNormalization",
"prenu_IntNormalization",
"prenu_Int_Ext_Normalization",
"glodiff",
"glodiff_int")
# Create an empty list to store the scatter plots for IViE
scatter_plots_IViE <- list()
# Iterate over each pair of cues for IViE
for (i in 1:(length(acoustic_cues) - 1)) {
for (j in (i + 1):length(acoustic_cues)) {
# Select the current pair of cues
cue1 <- acoustic_cues[i]
cue2 <- acoustic_cues[j]
# Create a subset of the scatter data for the current pair of cues in IViE
scatter_data_IViE <- IViE[, c(cue1, cue2, "utterance_type")]
# Create a scatter plot for the current pair of cues in IViE
scatter_plot_IViE <- ggplot(data = scatter_data_IViE, aes_string(x = cue2, y = cue1)) +
geom_point(color = ifelse(scatter_data_IViE$utterance_type == "dec", "red", "black")) +
stat_ellipse(aes(color = NA, fill = utterance_type), geom = "polygon", type = "norm", level = .95, alpha = 0.2) +
labs(x = cue2, y = cue1) +
scale_color_manual(values = c("red", "black")) +
scale_fill_manual(values = c("red", "black")) +
theme_minimal()
# Add the scatter plot to the list for IViE
scatter_plots_IViE[[paste(cue1, cue2, sep = " vs. ")]] <- scatter_plot_IViE
}
}
# Display each scatter plot separately for IViE
for (i in 1:length(scatter_plots_IViE)) {
print(scatter_plots_IViE[[i]])
}
# Create an empty list to store the scatter plots for SVBI
scatter_plots_SVBI <- list()
# Iterate over each pair of cues for SVBI
for (i in 1:(length(acoustic_cues) - 1)) {
for (j in (i + 1):length(acoustic_cues)) {
# Select the current pair of cues
cue1 <- acoustic_cues[i]
cue2 <- acoustic_cues[j]
# Create a subset of the scatter data for the current pair of cues in SVBI
scatter_data_SVBI <- SVBI[, c(cue1, cue2, "utterance_type")]
# Create a scatter plot for the current pair of cues in SVBI
scatter_plot_SVBI <- ggplot(data = scatter_data_SVBI, aes_string(x = cue2, y = cue1)) +
geom_point(color = ifelse(scatter_data_SVBI$utterance_type == "dec", "red", "black")) +
stat_ellipse(aes(color = NA, fill = utterance_type), geom = "polygon", type = "norm", level = .95, alpha = 0.2) +
labs(x = cue2, y = cue1) +
scale_color_manual(values = c("red", "black")) +
scale_fill_manual(values = c("red", "black")) +
theme_minimal()
# Add the scatter plot to the list for SVBI
scatter_plots_SVBI[[paste(cue1, cue2, sep = " vs. ")]] <- scatter_plot_SVBI
}
}
# Display each scatter plot separately for SVBI
for (i in 1:length(scatter_plots_SVBI)) {
print(scatter_plots_SVBI[[i]])
}
acoustic_cues <- c("final_F0", "fin_ExtNormalization", "fin_IntNormalization",
"fin_Int_Ext_Normalization", "prenuclear_F0", "prenu_ExtNormalization",
"prenu_IntNormalization", "prenu_Int_Ext_Normalization", "glodiff",
"glodiff_int")
# The cue we are interested in
target_cue <- "final_duration"
# Create an empty list to store the scatter plots for IViE
scatter_plots_IViE <- list()
# Iterate over each cue for IViE
for (i in 1:length(acoustic_cues)) {
# Select the current pair of cues
cue1 <- target_cue
cue2 <- acoustic_cues[i]
# Create a subset of the scatter data for the current pair of cues in IViE
scatter_data_IViE <- IViE[, c(cue1, cue2, "utterance_type")]
# Create a scatter plot for the current pair of cues in IViE
scatter_plot_IViE <- ggplot(data = scatter_data_IViE, aes_string(x = cue2, y = cue1)) +
geom_point(color = ifelse(scatter_data_IViE$utterance_type == "dec", "red", "black")) +
stat_ellipse(aes(color = NA, fill = utterance_type), geom = "polygon", type = "norm", level = .95, alpha = 0.2) +
labs(x = cue2, y = cue1) +
scale_color_manual(values = c("red", "black")) +
scale_fill_manual(values = c("red", "black")) +
theme_minimal()
# Add the scatter plot to the list for IViE
scatter_plots_IViE[[paste(cue1, cue2, sep = " vs. ")]] <- scatter_plot_IViE
}
# Display each scatter plot separately for IViE
for (i in 1:length(scatter_plots_IViE)) {
print(scatter_plots_IViE[[i]])
}
##save these plots into a folder
for (i in 1:length(scatter_plots_IViE)) {
# Create a file name for the plot
file_name <- paste0("scatter_plot_IViE_", i, ".png")
# Save the plot
ggsave(filename = file_name, plot = scatter_plots_IViE[[i]], width = 7, height = 7)
}
# A list for all acoustic cues used in the analysis
acoustic_cues <- c("final_F0", "fin_ExtNormalization", "fin_IntNormalization",
"fin_Int_Ext_Normalization", "prenuclear_F0", "prenu_ExtNormalization",
"prenu_IntNormalization", "prenu_Int_Ext_Normalization", "glodiff",
"glodiff_int")
# The cue we are interested in
target_cue <- "final_duration"
# Create an empty list to store the scatter plots for SVBI
scatter_plots_SVBI <- list()
# Iterate over each cue for SVBI
for (i in 1:length(acoustic_cues)) {
# Select the current pair of cues
cue1 <- target_cue
cue2 <- acoustic_cues[i]
# Create a subset of the scatter data for the current pair of cues in SVBI
scatter_data_SVBI <- SVBI[, c(cue1, cue2, "utterance_type")]
# Create a scatter plot for the current pair of cues in SVBI
scatter_plot_SVBI <- ggplot(data = scatter_data_SVBI, aes_string(x = cue2, y = cue1)) +
geom_point(color = ifelse(scatter_data_SVBI$utterance_type == "dec", "red", "black")) +
stat_ellipse(aes(color = NA, fill = utterance_type), geom = "polygon", type = "norm", level = .95, alpha = 0.2) +
labs(x = cue2, y = cue1) +
scale_color_manual(values = c("red", "black")) +
scale_fill_manual(values = c("red", "black")) +
theme_minimal()
# Add the scatter plot to the list for SVBI
scatter_plots_SVBI[[paste(cue1, cue2, sep = " vs. ")]] <- scatter_plot_SVBI
}
# Display each scatter plot separately for SVBI
for (i in 1:length(scatter_plots_SVBI)) {
print(scatter_plots_SVBI[[i]])
}
# Define common variables
excluded_columns <- c("final_duration", "prenuclear_F0", "prenu_ExtNormalization", "prenu_Int_Ext_Normalization", "initial_F0", "final_F0_mean",
"fin_ExtNormalization_mean", "prenuclear_F0_mean", "prenu_ExtNormalization_mean", "Nuclear_f0", "glodiff_int",
"fin_ExtNormalization")
cue_columns <- c("final_F0",
"fin_IntNormalization",
"fin_Int_Ext_Normalization",
"prenu_IntNormalization",
"glodiff")
# Create a function to perform operations for a specific dataset
process_dataset <- function(dataset, dataset_name) {
temp_dataset <- dataset
for (col in excluded_columns) {
temp_dataset[[col]] <- NULL
}
dataset_long <- temp_dataset %>%
pivot_longer(cols = all_of(cue_columns),
names_to = "cue_type",
values_to = "cue_value")
dataset_long$dataset <- dataset_name
return(dataset_long)
}
# Process IViE dataset
IViE_long <- process_dataset(IViE, "ivie")
# Process SVBI dataset
SVBI_long <- process_dataset(SVBI, "svbi")
SVBI_long
# added the talker column for talker specific models.
SVBI_long <- SVBI_long %>%
mutate(talker = paste(dialect, gender, speaker_id, sep = "-"))
SVBI_long
cue_types <- unique(IViE_long$cue_type)
cue_types
train_models <- function(data, grouping, cues, add_groups=TRUE) {
existing_groups <- data %>% groups()
models <-
data %>%
dplyr::group_by(.dots = grouping, add=add_groups) %>%
tidyr::nest() %>%
mutate(data = map(data, ~ cue_matrix(.x, cues)),
model = purrr::map(data,
~ list(mu    = apply(., 2, mean),
Sigma = sd(.))))
## if training groups were added, restore the original groups
if (add_groups) {
models %>% dplyr::group_by(.dots = existing_groups)
} else {
models
}
}
# Function to process dataset, create nested models, and store in a list
process_gen_dataset_models <- function(dataset, dataset_name, cue_types) {
# Create an empty list to store the nested models
models_list <- list()
# For each cue_type
for (cue in cue_types) {
# Filter data for the current cue type
data_filtered <- dataset %>% filter(cue_type == cue)
# Group and nest data for each combination of utterance_type, gender, and dialect
nest_data_filtered <- data_filtered %>%
group_by(utterance_type) %>%
nest()
# Apply train_models function and create a new column with models
nest_data_filtered <- nest_data_filtered %>%
mutate(models = map(data, ~train_models(.x,
grouping = "gender",
cues = "cue_value",
add_groups = TRUE)))
# Add the nested data frame with models to the list
models_list[[cue]] <- nest_data_filtered
}
# Add the dataset name to each element of the list
models_list <- lapply(models_list, function(x) { x$dataset <- dataset_name; return(x) })
return(models_list)
}
# Process IViE dataset and create nested models
utt.gen.models_list.IViE <- process_gen_dataset_models(IViE_long, "IViE", cue_types)
# Process SVBI dataset and create nested models
utt.gen.models_list.SVBI <- process_gen_dataset_models(SVBI_long, "SVBI", cue_types)
utt.gen.models_list.IViE
utt.gen.models_list.SVBI
# Function to process dataset, create nested models based on dialect, and store in a list
process_dia_dataset_models <- function(dataset, dataset_name, cue_types) {
# Create an empty list to store the nested models
models_list <- list()
# For each cue_type
for (cue in cue_types) {
# Filter data for the current cue type
data_filtered <- dataset %>% filter(cue_type == cue)
# Group and nest data for each combination of utterance_type, gender, and dialect
nest_data_filtered <- data_filtered %>%
group_by(utterance_type) %>%
nest()
# Apply train_models function and create a new column with models
nest_data_filtered <- nest_data_filtered %>%
mutate(models = map(data, ~train_models(.x,
grouping = "dialect",
cues = "cue_value",
add_groups = TRUE)))
# Add the nested data frame with models to the list
models_list[[cue]] <- nest_data_filtered
}
# Add the dataset name to each element of the list
models_list <- lapply(models_list, function(x) { x$dataset <- dataset_name; return(x) })
return(models_list)
}
# Process IViE dataset and create nested models based on dialect
utt.dia.models_list.IViE <- process_dia_dataset_models(IViE_long, "IViE", cue_types)
# Process SVBI dataset and create nested models based on dialect
utt.dia.models_list.SVBI <- process_dia_dataset_models(SVBI_long, "SVBI", cue_types)
utt.dia.models_list.SVBI
utt.dia.models_list.IViE
# Function to process dataset, create nested models based on utterance_type, gender, and dialect, and store in a list
process_gen_dia_dataset_models <- function(dataset, dataset_name, cue_types) {
# Create an empty list to store the nested models
models_list <- list()
# For each cue_type
for (cue in cue_types) {
# Filter data for the current cue type
data_filtered <- dataset %>% filter(cue_type == cue)
# Group and nest data for each combination of utterance_type, gender, and dialect
nest_data_filtered <- data_filtered %>%
group_by(utterance_type, gender) %>%
nest()
# Apply train_models function and create a new column with models
nest_data_filtered <- nest_data_filtered %>%
mutate(models = map(data, ~train_models(.x,
grouping = "dialect",
cues = "cue_value",
add_groups = TRUE)))
# Add the nested data frame with models to the list
models_list[[cue]] <- nest_data_filtered
}
# Add the dataset name to each element of the list
models_list <- lapply(models_list, function(x) { x$dataset <- dataset_name; return(x) })
return(models_list)
}
# Process IViE dataset and create nested models based on utterance_type, gender, and dialect
utt.gen.dia.models_list.IViE <- process_gen_dia_dataset_models(IViE_long, "IViE", cue_types)
# Process SVBI dataset and create nested models based on utterance_type, gender, and dialect
utt.gen.dia.models_list.SVBI <- process_gen_dia_dataset_models(SVBI_long, "SVBI", cue_types)
utt.gen.dia.models_list.IViE$glodiff
utt.gen.dia.models_list.SVBI$final_F0$gender
# Iterate over the cues
for (cue in names(utt.gen.dia.models_list.IViE)) {
# Create a new vector that represents the desired order
desired_order <- paste(utt.gen.dia.models_list.SVBI[[cue]]$gender,
utt.gen.dia.models_list.SVBI[[cue]]$utterance_type,
sep="_")
# Create a similar vector for the current order in IViE list
current_order_IViE <- paste(utt.gen.dia.models_list.IViE[[cue]]$gender,
utt.gen.dia.models_list.IViE[[cue]]$utterance_type,
sep="_")
# Generate a vector of indices that would arrange current_order_IViE to match desired_order
order_index <- match(desired_order, current_order_IViE)
# Reorder the rows of the data frame in IViE based on this index
utt.gen.dia.models_list.IViE[[cue]] <- utt.gen.dia.models_list.IViE[[cue]][order_index, ]
}
# Function to process dataset, create nested models, and store in a list
process_tal_dataset_models <- function(dataset, dataset_name, cue_types) {
# Create an empty list to store the nested models
models_list <- list()
# For each cue_type
for (cue in cue_types) {
# Filter data for the current cue type
data_filtered <- dataset %>% filter(cue_type == cue)
# Group and nest data for each combination of utterance_type, speaker, and dialect
nest_data_filtered <- data_filtered %>%
group_by(utterance_type) %>%
nest()
# Apply train_models function and create a new column with models
nest_data_filtered <- nest_data_filtered %>%
mutate(models = map(data, ~train_models(.x,
grouping = "talker",  # Change to speaker
cues = "cue_value",
add_groups = TRUE)))
# Add the nested data frame with models to the list
models_list[[cue]] <- nest_data_filtered
}
# Add the dataset name to each element of the list
models_list <- lapply(models_list, function(x) { x$dataset <- dataset_name; return(x) })
return(models_list)
}
# Process SVBI dataset and create nested models
utt.tal.models_list.SVBI <- process_tal_dataset_models(SVBI_long, "SVBI", cue_types)
utt.tal.models_list.SVBI
# Function to process dataset, create nested models based on utterance_type and dataset, and store in a list
process_mar_dataset_models <- function(dataset, dataset_name, cue_types) {
# Create an empty list to store the nested models
models_list <- list()
# For each cue_type
for (cue in cue_types) {
# Filter data for the current cue type
data_filtered <- dataset %>% filter(cue_type == cue)
# Group and nest data for each combination of utterance_type and dataset
nest_data_filtered <- data_filtered %>%
group_by(utterance_type) %>%
nest()
# Apply train_models function and create a new column with models
nest_data_filtered <- nest_data_filtered %>%
mutate(models = map(data, ~train_models(.x,
grouping = "dataset",
cues = "cue_value",
add_groups = TRUE)))
# Add the nested data frame with models to the list
models_list[[cue]] <- nest_data_filtered
}
# Add the dataset name to each element of the list
models_list <- lapply(models_list, function(x) { x$dataset <- dataset_name; return(x) })
return(models_list)
}
# Process IViE dataset and create nested models based on utterance_type and dataset
utt.mar.models_list.IViE <- process_mar_dataset_models(IViE_long, "IViE", cue_types)
# Process SVBI dataset and create nested models based on utterance_type and dataset
utt.mar.models_list.SVBI <- process_mar_dataset_models(SVBI_long, "SVBI", cue_types)
utt.mar.models_list.IViE
utt.mar.models_list.SVBI
KL_uvnorm <- function(mu1, sigma1, mu2, sigma2) {
assert_that(is.numeric(mu1))
assert_that(is.numeric(mu2))
# variance for true distribution
sigma1 <- as.numeric(sigma1)
# variance for marginal distribution
sigma2 <- as.numeric(sigma2)
assert_that(is.numeric(sigma1))
assert_that(is.numeric(sigma2))
## ------------------
## (Dividing by log(2) gives KL in bits)
kl <- (log(sigma2/sigma1) + (sigma1^2 + (mu1 - mu2)^2) / (2 * sigma2^2) - 0.5) / log(2)
return(kl)
}
KL_mods <- function(mod1, mod2) {
KL_uvnorm(mod1$mu, mod1$Sigma, mod2$mu, mod2$Sigma)
}
load("./RData/gen_KL.RData")
gen.KL.IViE
gen.KL.IViE$p_values
gen.KL.SVBI$kl_values
gen.KL.IViE$kl_values
create_df <- function(cue, data) {
data.frame(
Gender = c("female_dec", "male_dec", "female_dqu", "male_dqu"),
p_values = c(data$p_values[[cue]][[1]]$female,
data$p_values[[cue]][[1]]$male,
data$p_values[[cue]][[2]]$female,
data$p_values[[cue]][[2]]$male),
kl_values = c(data$kl_values[[cue]][[1]]$female,
data$kl_values[[cue]][[1]]$male,
data$kl_values[[cue]][[2]]$female,
data$kl_values[[cue]][[2]]$male)
)
}
cues <- c("final_F0", "fin_IntNormalization", "fin_Int_Ext_Normalization", "prenu_IntNormalization", "glodiff")
tables.SVBI <- setNames(lapply(cues, create_df, data = gen.KL.SVBI), cues)
# list of table captions
captions <- c("Final syllable F0", "Final syllable F0 Internal Normalization", "Final syllable F0 Internal+External Normalization", "Prenuclear accent Internal Normalization", "Global F0 differences")
for (i in seq_along(tables.SVBI)) {
print(knitr::kable(tables[[i]], caption = captions[i], digits = 3, row.names = FALSE))
}
create_df <- function(cue, data) {
data.frame(
Gender = c("female_dec", "male_dec", "female_dqu", "male_dqu"),
p_values = c(data$p_values[[cue]][[1]]$female,
data$p_values[[cue]][[1]]$male,
data$p_values[[cue]][[2]]$female,
data$p_values[[cue]][[2]]$male),
kl_values = c(data$kl_values[[cue]][[1]]$female,
data$kl_values[[cue]][[1]]$male,
data$kl_values[[cue]][[2]]$female,
data$kl_values[[cue]][[2]]$male)
)
}
cues <- c("final_F0", "fin_IntNormalization", "fin_Int_Ext_Normalization", "prenu_IntNormalization", "glodiff")
# Use lapply to apply the function to each cue
tables.IViE <- setNames(lapply(cues, create_df, data = gen.KL.IViE), cues)
tables.SVBI <- setNames(lapply(cues, create_df, data = gen.KL.SVBI), cues)
# list of table captions
captions <- c("Final syllable F0", "Final syllable F0 Internal Normalization", "Final syllable F0 Internal+External Normalization", "Prenuclear accent Internal Normalization", "Global F0 differences")
# print each table with knitr::kable()
for (i in seq_along(tables.IViE)) {
print(knitr::kable(tables.IViE[[i]], caption = captions[i], digits = 3, row.names = FALSE))
}
for (i in seq_along(tables.SVBI)) {
print(knitr::kable(tables.SVBI[[i]], caption = captions[i], digits = 3, row.names = FALSE))
}
create_df_IViE <- function(cue, data) {
data.frame(
Dialects = rep(c("Belfast", "Cambridge", "Dublin", "London", "Leeds",
"Newcastle", "Bradford", "Liverpool", "Cardiff"), times = 2),
Conditions = c(rep("dec", times = 9), rep("dqu", times = 9)),
p_values = c(data$p_values[[cue]][[1]],
data$p_values[[cue]][[2]]),
kl_values = c(data$kl_values[[cue]][[1]],
data$kl_values[[cue]][[2]])
)
}
create_df_SVBI <- function(cue, data) {
data.frame(
Dialects = rep(c("Belfast", "Cambridge", "Newcastle"), times = 2),
Conditions = c(rep("dec", times = 3), rep("dqu", times = 3)),
P_values = c(data$p_values[[cue]][[1]], data$p_values[[cue]][[2]]),
KL_values = c(data$kl_values[[cue]][[1]], data$kl_values[[cue]][[2]])
)
}
cues <- c("final_F0", "fin_IntNormalization", "fin_Int_Ext_Normalization", "prenu_IntNormalization", "glodiff")
# Use lapply to apply the function to each cue
dia.KL.IViE.table <- setNames(lapply(cues, create_df_IViE, data = dia.KL.IViE), cues)
load("./RData/dia_KL.RData")
dia.KL.IViE
dia.KL.SVBI
create_df_IViE <- function(cue, data) {
data.frame(
Dialects = rep(c("Belfast", "Cambridge", "Dublin", "London", "Leeds",
"Newcastle", "Bradford", "Liverpool", "Cardiff"), times = 2),
Conditions = c(rep("dec", times = 9), rep("dqu", times = 9)),
p_values = c(data$p_values[[cue]][[1]],
data$p_values[[cue]][[2]]),
kl_values = c(data$kl_values[[cue]][[1]],
data$kl_values[[cue]][[2]])
)
}
create_df_SVBI <- function(cue, data) {
data.frame(
Dialects = rep(c("Belfast", "Cambridge", "Newcastle"), times = 2),
Conditions = c(rep("dec", times = 3), rep("dqu", times = 3)),
P_values = c(data$p_values[[cue]][[1]], data$p_values[[cue]][[2]]),
KL_values = c(data$kl_values[[cue]][[1]], data$kl_values[[cue]][[2]])
)
}
cues <- c("final_F0", "fin_IntNormalization", "fin_Int_Ext_Normalization", "prenu_IntNormalization", "glodiff")
# Use lapply to apply the function to each cue
dia.KL.IViE.table <- setNames(lapply(cues, create_df_IViE, data = dia.KL.IViE), cues)
dia.KL.SVBI.table <- setNames(lapply(cues, create_df_SVBI, data = dia.KL.SVBI), cues)
# list of table captions
captions <- c("Final syllable F0", "Final syllable F0 Internal Normalization", "Final syllable F0 Internal+Extermal Normalization", "Prenuclear accent Internal Normalization", "Global F0 differences")
# print each table with knitr::kable()
for (i in seq_along(dia.KL.IViE.table)) {
print(knitr::kable(dia.KL.IViE.table[[i]], caption = captions[i], digits = 3, row.names = FALSE))
}
for (i in seq_along(dia.KL.SVBI.table)) {
print(knitr::kable(dia.KL.SVBI.table[[i]], caption = captions[i], digits = 3, row.names = FALSE))
}
